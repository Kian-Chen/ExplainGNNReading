<!doctype html><html lang=zh class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Explainable GNN Reading"><meta name=author content=Kian-Chen><link href=https://Kian-Chen.github.io/ExplainGNNReading/ rel=canonical><link rel=icon href=assets/icon.svg><meta name=generator content="mkdocs-1.5.3, mkdocs-material-9.5.4"><title>Explainable GNN Reading</title><link rel=stylesheet href=assets/stylesheets/main.50c56a3b.min.css><link rel=stylesheet href=assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto+Slab:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto Slab";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config",""),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#paper-index-of-xai-for-gnns class=md-skip> 跳转至 </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=页眉> <a href=. title="Explainable GNN Reading" class="md-header__button md-logo" aria-label="Explainable GNN Reading" data-md-component=logo> <img src=assets/icon.svg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Explainable GNN Reading </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Paper Index </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=indigo aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg> </label> <input class=md-option data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme=slate data-md-color-primary=black data-md-color-accent=indigo aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg> </label> </form> <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=搜索 placeholder=搜索 autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg> </label> <nav class=md-search__options aria-label=查找> <a href=javascript:void(0) class="md-search__icon md-icon" title=分享 aria-label=分享 data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=清空当前内容 aria-label=清空当前内容 tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> 正在初始化搜索引擎 </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/Kian-Chen/ExplainGNNReading title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> ExplainGNNReading </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" aria-label=导航栏 data-md-level=0> <label class=md-nav__title for=__drawer> <a href=. title="Explainable GNN Reading" class="md-nav__button md-logo" aria-label="Explainable GNN Reading" data-md-component=logo> <img src=assets/icon.svg alt=logo> </a> Explainable GNN Reading </label> <div class=md-nav__source> <a href=https://github.com/Kian-Chen/ExplainGNNReading title=前往仓库 class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </div> <div class=md-source__repository> ExplainGNNReading </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Paper Index </span> <span class="md-nav__icon md-icon"></span> </label> <a href=. class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Paper Index </span> </a> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#surveys class=md-nav__link> <span class=md-ellipsis> Surveys </span> </a> </li> <li class=md-nav__item> <a href=#platforms class=md-nav__link> <span class=md-ellipsis> Platforms </span> </a> </li> <li class=md-nav__item> <a href=#most-influential-papers-selected-by-cogdl class=md-nav__link> <span class=md-ellipsis> Most Influential Papers selected by Cogdl </span> </a> </li> <li class=md-nav__item> <a href=#year-2024 class=md-nav__link> <span class=md-ellipsis> Year 2024 </span> </a> </li> <li class=md-nav__item> <a href=#year-2023 class=md-nav__link> <span class=md-ellipsis> Year 2023 </span> </a> </li> <li class=md-nav__item> <a href=#year-2022 class=md-nav__link> <span class=md-ellipsis> Year 2022 </span> </a> </li> <li class=md-nav__item> <a href=#year-2021 class=md-nav__link> <span class=md-ellipsis> Year 2021 </span> </a> </li> <li class=md-nav__item> <a href=#year-2020-and-before class=md-nav__link> <span class=md-ellipsis> Year 2020 and Before </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label=目录> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 目录 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#surveys class=md-nav__link> <span class=md-ellipsis> Surveys </span> </a> </li> <li class=md-nav__item> <a href=#platforms class=md-nav__link> <span class=md-ellipsis> Platforms </span> </a> </li> <li class=md-nav__item> <a href=#most-influential-papers-selected-by-cogdl class=md-nav__link> <span class=md-ellipsis> Most Influential Papers selected by Cogdl </span> </a> </li> <li class=md-nav__item> <a href=#year-2024 class=md-nav__link> <span class=md-ellipsis> Year 2024 </span> </a> </li> <li class=md-nav__item> <a href=#year-2023 class=md-nav__link> <span class=md-ellipsis> Year 2023 </span> </a> </li> <li class=md-nav__item> <a href=#year-2022 class=md-nav__link> <span class=md-ellipsis> Year 2022 </span> </a> </li> <li class=md-nav__item> <a href=#year-2021 class=md-nav__link> <span class=md-ellipsis> Year 2021 </span> </a> </li> <li class=md-nav__item> <a href=#year-2020-and-before class=md-nav__link> <span class=md-ellipsis> Year 2020 and Before </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a href=https://github.com/Kian-Chen/ExplainGNNReading/edit/master/docs/index.md title=编辑此页 class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4v-2m10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1 2.1 2.1Z"/></svg> </a> <a href=https://github.com/Kian-Chen/ExplainGNNReading/raw/master/docs/index.md title=查看本页的源代码 class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.15 8.15 0 0 1-1.23-2Z"/></svg> </a> <h1 id=paper-index-of-xai-for-gnns><strong>Paper Index of XAI for GNNs</strong><a class=headerlink href=#paper-index-of-xai-for-gnns title="Permanent link">&para;</a></h1> <p>Papers about the explainability of GNNs</p> <h2 id=surveys>Surveys<a class=headerlink href=#surveys title="Permanent link">&para;</a></h2> <ol> <li>[Proceedings of the IEEE 24] <strong>Trustworthy Graph Neural Networks: Aspects, Methods and Trends</strong> <a href=https://arxiv.org/abs/2205.07424>paper</a></li> <li>[Preprint 24] <strong>Graph-Based Explainable AI: A Comprehensive Survey</strong> <a href=https://hal.science/hal-04660442/ >paper</a></li> <li>[Arixv 23] <strong>A Survey on Explainability of Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2306.01958>paper</a></li> <li>[ACM computing survey] <strong>A Survey on Graph Counterfactual Explanations: Definitions, Methods, Evaluation, and Research Challenges</strong> <a href=https://dl.acm.org/doi/abs/10.1145/3618105>paper</a></li> <li>[TPAMI 22]<strong>Explainability in graph neural networks: A taxonomic survey</strong>. <em>Yuan Hao, Yu Haiyang, Gui Shurui, Ji Shuiwang</em>. <a href=https://arxiv.org/pdf/2012.15445.pdf>paper</a></li> <li>[Arxiv 22]<strong>A Survey of Explainable Graph Neural Networks: Taxonomy and Evaluation Metrics</strong> <a href=https://arxiv.org/pdf/2207.12599.pdf>paper</a></li> <li>[Arxiv 22] <strong>A Survey of Trustworthy Graph Learning: Reliability, Explainability, and Privacy Protection</strong> <a href=https://arxiv.org/abs/2205.10014>paper</a></li> <li>[Big Data 2022]<strong>A Survey of Explainable Graph Neural Networks for Cyber Malware Analysis</strong> <a href=https://ieeexplore.ieee.org/abstract/document/10020943>paper</a></li> <li>[Arxiv 23] <strong>A Comprehensive Survey on Trustworthy Graph Neural Networks: Privacy, Robustness, Fairness, and Explainability</strong><a href=https://arxiv.org/abs/2204.08570>paper</a></li> <li>[Arxiv 22] <strong>Explaining the Explainers in Graph Neural Networks: a Comparative Study</strong> <a href=https://arxiv.org/pdf/2210.15304.pdf>paper</a></li> <li>[Book 23] <strong>Generative Explanation for Graph Neural Network: Methods and Evaluation</strong> <a href=http://sites.computer.org/debull/A23june/p64.pdf>paper</a></li> </ol> <h2 id=platforms>Platforms<a class=headerlink href=#platforms title="Permanent link">&para;</a></h2> <ol> <li><strong>PyTorch Geometric</strong> <a href=https://pytorch-geometric.readthedocs.io/en/latest/tutorial/explain.html>[Document]</a> <a href=https://medium.com/@pytorch_geometric/graph-machine-learning-explainability-with-pyg-ff13cffc23c2>[Blog]</a></li> <li><strong>DIG: A Turnkey Library for Diving into Graph Deep Learning Research</strong> <a href=https://www.jmlr.org/papers/v22/21-0343.html>paper</a> <a href=https://github.com/divelab/DIG>Code</a></li> <li><strong>GraphXAI: Evaluating Explainability for Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2208.09339v2>paper</a> <a href=https://github.com/mims-harvard/graphxai>Code</a></li> <li><strong>GraphFramEx: Towards Systematic Evaluation of Explainability Methods for Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2206.09677>paper</a> <a href=https://github.com/graphframex/graphframex>Code</a></li> <li><strong>GNNExplainer and PGExplainer</strong> <a href="https://openreview.net/forum?id=8JHrucviUf">paper</a> <a href=https://github.com/LarsHoldijk/RE-ParameterizedExplainerForGraphNeuralNetworks>Code</a></li> <li><strong>BAGEL: A Benchmark for Assessing Graph Neural Network Explanations</strong> <a href=https://arxiv.org/abs/2206.13983>[paper]</a><a href=https://github.com/mandeep-rathee/bagel-benchmark>Code</a></li> </ol> <h2 id=most-influential-papers-selected-by-cogdl>Most Influential Papers selected by <a href=https://github.com/THUDM/cogdl/blob/master/gnn_papers.md#explainability>Cogdl</a><a class=headerlink href=#most-influential-papers-selected-by-cogdl title="Permanent link">&para;</a></h2> <ol> <li><strong>Explainability in graph neural networks: A taxonomic survey</strong>. <em>Yuan Hao, Yu Haiyang, Gui Shurui, Ji Shuiwang</em>. ARXIV 2020. <a href=https://arxiv.org/pdf/2012.15445.pdf>paper</a></li> <li><strong>Gnnexplainer: Generating explanations for graph neural networks</strong>. <em>Ying Rex, Bourgeois Dylan, You Jiaxuan, Zitnik Marinka, Leskovec Jure</em>. NeurIPS 2019. <a href=https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7138248/ >paper</a> <a href=https://github.com/RexYing/gnn-model-explainer>code</a></li> <li><strong>Explainability methods for graph convolutional neural networks</strong>. <em>Pope Phillip E, Kolouri Soheil, Rostami Mohammad, Martin Charles E, Hoffmann Heiko</em>. CVPR 2019.<a href=https://openaccess.thecvf.com/content_CVPR_2019/papers/Pope_Explainability_Methods_for_Graph_Convolutional_Neural_Networks_CVPR_2019_paper.pdf>paper</a></li> <li><strong>Parameterized Explainer for Graph Neural Network</strong>. <em>Luo Dongsheng, Cheng Wei, Xu Dongkuan, Yu Wenchao, Zong Bo, Chen Haifeng, Zhang Xiang</em>. NeurIPS 2020. <a href=https://arxiv.org/abs/2011.04573>paper</a> <a href=https://github.com/flyingdoog/PGExplainer>code</a></li> <li><strong>Xgnn: Towards model-level explanations of graph neural networks</strong>. <em>Yuan Hao, Tang Jiliang, Hu Xia, Ji Shuiwang</em>. KDD 2020. <a href=https://dl.acm.org/doi/pdf/10.1145/3394486.3403085>paper</a>. </li> <li><strong>Evaluating Attribution for Graph Neural Networks</strong>. <em>Sanchez-Lengeling Benjamin, Wei Jennifer, Lee Brian, Reif Emily, Wang Peter, Qian Wesley, McCloskey Kevin, Colwell Lucy, Wiltschko Alexander</em>. NeurIPS 2020.<a href=https://proceedings.neurips.cc/paper/2020/file/417fbbf2e9d5a28a855a11894b2e795a-Paper.pdf>paper</a></li> <li><strong>PGM-Explainer: Probabilistic Graphical Model Explanations for Graph Neural Networks</strong>. <em>Vu Minh, Thai My T.</em>. NeurIPS 2020.<a href=https://arxiv.org/pdf/2010.05788.pdf>paper</a></li> <li><strong>Explanation-based Weakly-supervised Learning of Visual Relations with Graph Networks</strong>. <em>Federico Baldassarre and Kevin Smith and Josephine Sullivan and Hossein Azizpour</em>. ECCV 2020.<a href=https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123730613.pdf>paper</a></li> <li><strong>GCAN: Graph-aware Co-Attention Networks for Explainable Fake News Detection on Social Media</strong>. <em>Lu, Yi-Ju and Li, Cheng-Te</em>. ACL 2020.<a href=https://arxiv.org/pdf/2004.11648.pdf>paper</a></li> <li><strong>On Explainability of Graph Neural Networks via Subgraph Explorations</strong>. <em>Yuan Hao, Yu Haiyang, Wang Jie, Li Kang, Ji Shuiwang</em>. ICML 2021.<a href=https://arxiv.org/pdf/2102.05152.pdf>paper</a></li> </ol> <h2 id=year-2024>Year 2024<a class=headerlink href=#year-2024 title="Permanent link">&para;</a></h2> <ol> <li>[NeurIPS 24] <strong>RegExplainer: Generating Explanations for Graph Neural Networks in Regression Task</strong> <a href=https://arxiv.org/abs/2307.07840>[paper]</a></li> <li>[NeurIPS 24] <strong>GraphTrail: Translating GNN Predictions into Human-Interpretable Logical Rules</strong><a href=https://nips.cc/virtual/2024/poster/94172>[paper]</a></li> <li>[ICML 24] <strong>Generating In-Distribution Proxy Graphs for Explaining Graph Neural Networks</strong><a href=https://arxiv.org/abs/2402.02036>[paper]</a></li> <li>[ICML 24] <strong>Predicting and Interpreting Energy Barriers of Metallic Glasses with Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2401.08627>[paper]</a></li> <li>[ICML 24] <strong>Graph Neural Network Explanations are Fragile</strong> <a href=https://arxiv.org/pdf/2406.03193>[paper]</a></li> <li>[ICML 24] <strong>How Interpretable Are Interpretable Graph Neural Networks?</strong> <a href=https://arxiv.org/abs/2406.07955>[paper]</a></li> <li>[ICML 24] <strong>Feature Attribution with Necessity and Sufficiency via Dual-stage Perturbation Test for Causal Explanation</strong><a href=https://arxiv.org/abs/2402.08845>[paper]</a></li> <li>[ICML 24] <strong>Explaining Graph Neural Networks via Structure-aware Interaction Index</strong> <a href=https://icml.cc/virtual/2024/poster/34550>[paper]</a></li> <li>[ICML 24] <strong>EiG-Search: Generating Edge-Induced Subgraphs for GNN Explanation in Linear Time</strong> <a href=https://arxiv.org/abs/2405.01762>[paper]</a></li> <li>[ICLR 24] <strong>GraphChef: Decision-Tree Recipes to Explain Graph Neural Networks</strong> <a href="https://openreview.net/forum?id=IjMUGuUmBI">[paper]</a></li> <li>[ICLR 24] <strong>GOAt: Explaining Graph Neural Networks via Graph Output Attribution</strong> <a href="https://openreview.net/forum?id=2Q8TZWAHv4">[paper]</a></li> <li>[ICLR 24] <strong>Towards Robust Fidelity for Evaluating Explainability of Graph Neural Networks</strong> <a href="https://openreview.net/forum?id=up6hr4hIQH">[paper]</a></li> <li>[ICLR 24] <strong>GNNX-BENCH: Unravelling the Utility of Perturbation-based GNN Explainers through In-depth Benchmarking</strong> <a href=https://arxiv.org/abs/2310.01794>[paper]</a></li> <li>[ICLR 24] <strong>UNR-Explainer: Counterfactual Explanations for Unsupervised Node Representation Learning Models</strong> <a href="https://openreview.net/forum?id=0j9ZDzMPqr">[paper]</a></li> <li>[TPAMI 24] <strong>Towards Inductive and Efficient Explanations for Graph Neural Networks</strong><a href=https://ieeexplore.ieee.org/abstract/document/10423141>[paper]</a></li> <li>[TMLR 24] <strong>InduCE: Inductive Counterfactual Explanations for Graph Neural Networks</strong> <a href="https://openreview.net/forum?id=RZPN8cgqST">[paper]</a></li> <li>[PLDI 24] <strong>PL4XGL: A Programming Language Approach to Explainable Graph Learning</strong><a href=https://dl.acm.org/doi/10.1145/3656464>[paper]</a></li> <li>[Usenix Security 24] <strong>INSIGHT: Attacking Industry-Adopted Learning Resilient Logic Locking Techniques Using Explainable Graph Neural Network</strong><a href=https://www.usenix.org/conference/usenixsecurity24/presentation/mankali>[paper]</a></li> <li>[SIGMOD 24]<strong>View-based Explanations for Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2401.02086>[paper]</a></li> <li>[Thesis UCLA] <strong>Explainable Artificial Intelligence for Graph Data</strong><a href=https://escholarship.org/uc/item/6bf1g6dc>[paper]</a></li> <li>[Thesis UVA] <strong>Algorithmic Fairness in Graph Machine Learning: Explanation, Optimization, and Certification</strong><a href=https://www.proquest.com/docview/3083271574>[paper]</a></li> <li>[KDD 24] <strong>SEFraud: Graph-based Self-Explainable Fraud Detection via Interpretative Mask Learning</strong><a href=https://arxiv.org/abs/2406.11389>[paper]</a></li> <li>[KDD 24] <strong>Self-Explainable Temporal Graph Networks based on Graph Information Bottleneck</strong><a href=https://arxiv.org/abs/2406.13214>[paper]</a></li> <li>[KDD 24] <strong>Unveiling Global Interactive Patterns across Graphs: Towards Interpretable Graph Neural Networks</strong><a href=https://arxiv.org/abs/2407.01979>[paper]</a></li> <li>[ICDE 24] <strong>Generating Robust Counterfactual Witnesses for Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2404.19519>[paper]</a></li> <li>[ICDE 24] <strong>SES: Bridging the Gap Between Explainability and Prediction of Graph Neural Networks</strong><a href=https://arxiv.org/abs/2407.11358>[paper]</a></li> <li>[ICSE 24] <strong>Coca: Improving and Explaining Graph Neural Network-Based Vulnerability Detection Systems</strong><a href=https://arxiv.org/abs/2401.14886>[paper]</a></li> <li>[AAAI 24] <strong>Generating Diagnostic and Actionable Explanations for Fair Graph Neural Networks</strong> <a href=https://ojs.aaai.org/index.php/AAAI/article/view/30168>[paper]</a></li> <li>[AAAI 24] <strong>Stratifed GNN Explanations through Sufficient Expansion</strong><a href=https://ojs.aaai.org/index.php/AAAI/article/view/29180>[paper]</a></li> <li>[AAAI 24] <strong>Factorized Explainer for Graph Neural Networks</strong><a href=https://arxiv.org/abs/2312.05596>[paper]</a></li> <li>[AAAI 24] <strong>Self-Interpretable Graph Learning with Sufficient and Necessary Explanations</strong></li> <li>[AAAI 24] <strong>Explainable Origin-Destination Crowd Flow Interpolation via Variational Multi-Modal Recurrent Graph Auto-Encoder</strong> <a href=https://ojs.aaai.org/index.php/AAAI/article/view/28796>[paper]</a></li> <li>[AISTATS 24] <strong>Two Birds with One Stone: Enhancing Uncertainty Quantification and Interpretability with Graph Functional Neural Process</strong> <a href=https://proceedings.mlr.press/v238/kong24a.html>[paper]</a></li> <li>[WWW 24] <strong>Game-theoretic Counterfactual Explanation for Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2402.06030>[paper]</a></li> <li>[WWW 24] <strong>EXGC: Bridging Efficiency and Explainability in Graph Condensation</strong><a href=https://arxiv.org/abs/2402.05962>[paper]</a></li> <li>[WWW 24] <strong>Adversarial Mask Explainer for Graph Neural Networks</strong> <a href=https://dl.acm.org/doi/abs/10.1145/3589334.3645608>[paper]</a></li> <li>[WWW 24] <strong>Globally Interpretable Graph Learning via Distribution Matching</strong><a href=https://arxiv.org/abs/2306.10447>[paper]</a></li> <li>[WWW 24] <strong>GNNShap: Scalable and Accurate GNN Explanation using Shapley Values</strong> <a href=https://dl.acm.org/doi/abs/10.1145/3589334.3645599>[paper]</a></li> <li>[TAI 24] <strong>Learning Counterfactual Explanation of Graph Neural Networks via Generative Flow Network</strong><a href=https://ieeexplore.ieee.org/document/10496445>[paper]</a></li> <li>[IEEE TMI 24] <strong>Multi-Modal Diagnosis of Alzheimer’s Disease using Interpretable Graph Convolutional Networks</strong><a href=https://ieeexplore.ieee.org/abstract/document/10606492>[paper]</a></li> <li>[IEEE IoT 24] <strong>EXVul: Toward Effective and Explainable Vulnerability Detection for IoT Devices</strong><a href=https://ieeexplore.ieee.org/document/10479158>[paper]</a></li> <li>[ECML/PKDD 24] <strong>Towards Few-shot Self-explaining Graph Neural Networks</strong><a href=https://arxiv.org/abs/2408.07340>[paper]</a></li> <li>[SDM 24] <strong>XGExplainer: Robust Evaluation-based Explanation for Graph Neural Networks</strong><a href=https://epubs.siam.org/doi/abs/10.1137/1.9781611978032.8>[paper]</a></li> <li>[DASFAA 24] <strong>Multi-objective Graph Neural Network Explanatory Model with Local and Global Information Preservation</strong><a href=https://link.springer.com/chapter/10.1007/978-981-97-5572-1_20>[paper]</a></li> <li>[ISSTA 2024] <strong>Graph Neural Networks for Vulnerability Detection: A Counterfactual Explanation</strong> <a href=https://arxiv.org/abs/2404.15687>[paper]</a></li> <li>[KBS 24] <strong>Shapley-based graph explanation in embedding space</strong><a href=https://www.sciencedirect.com/science/article/abs/pii/S0950705124008785?via%3Dihub>[paper]</a></li> <li>[KBS 24] <strong>GEAR: Learning graph neural network explainer via adjusting gradients</strong><a href=https://www.sciencedirect.com/science/article/abs/pii/S0950705124010025>[paper]</a></li> <li>[IEEE TNSM 24] <strong>Ensemble Graph Attention Networks for Cellular Network Analytics: From Model Creation to Explainability</strong><a href=https://ieeexplore.ieee.org/abstract/document/10622099>[paper]</a></li> <li>[IEEE TNSE 24] <strong>GAXG: A Global and Self-adaptive Optimal Graph Topology Generation Framework for Explaining Graph Neural Networks</strong><a href=https://ieeexplore.ieee.org/abstract/document/10614894>[paper]</a></li> <li>[IEEE TETCI 24] <strong>GF-LRP: A Method for Explaining Predictions Made by Variational Graph Auto-Encoders</strong><a href=https://ieeexplore.ieee.org/abstract/document/10586750>[paper]</a></li> <li>[AAAI workshop] <strong>Semi-Supervised Graph Representation Learning with Human-centric Explanation for Predicting Fatty Liver Disease</strong><a href=https://arxiv.org/abs/2403.02786>[paper]</a></li> <li>[xAI 24] <strong>Global Concept Explanations for Graphs by Contrastive Learning</strong> <a href=https://arxiv.org/abs/2404.16532>[paper]</a></li> <li>[Arxiv 24.09] <strong>PAGE: Parametric Generative Explainer for Graph Neural Network</strong> <a href=https://arxiv.org/abs/2408.14042>[paper]</a></li> <li>[Arxiv 24.09] <strong>Higher Order Structures For Graph Explanations</strong> <a href=https://arxiv.org/abs/2406.03253v4>[paper]</a></li> <li>[Arxiv 24.08] <strong>SE-SGformer: A Self-Explainable Signed Graph Transformer for Link Sign Prediction</strong><a href=https://arxiv.org/abs/2408.08754>[paper]</a></li> <li>[Preprint 24.08] <strong>CIDER: Counterfactual-Invariant Diffusion-based GNN Explainer for Causal Subgraph Inference</strong><a href=https://www.researchsquare.com/article/rs-4814778/v1>[paper]</a></li> <li>[Arxiv 24.07] <strong>LLMExplainer: Large Language Model based Bayesian Inference for Graph Explanation Generation</strong><a href=https://arxiv.org/abs/2407.15351>[paper]</a></li> <li>[Arxiv 24.07] <strong>xAI-Drop: Don't Use What You Cannot Explain</strong><a href=https://arxiv.org/abs/2407.20067>[paper]</a></li> <li>[Arxiv 24.07] <strong>Explaining Graph Neural Networks for Node Similarity on Graphs</strong><a href=https://arxiv.org/abs/2407.07639>[paper]</a></li> <li>[Arxiv 24.07] <strong>SLInterpreter: An Exploratory and Iterative Human-AI Collaborative System for GNN-based Synthetic Lethal Prediction</strong><a href=https://arxiv.org/abs/2407.14770>[paper]</a></li> <li>[Arxiv 24.07] <strong>Graph Neural Network Causal Explanation via Neural Causal Models</strong><a href=https://arxiv.org/abs/2407.09378>[paper]</a></li> <li>[Arxiv 24.06] <strong>GNNAnatomy: Systematic Generation and Evaluation of Multi-Level Explanations for Graph Neural Networks</strong><a href=https://arxiv.org/abs/2406.04548>[paper]</a></li> <li>[Arxiv 24.06] <strong>On GNN explanability with activation rules</strong><a href=https://arxiv.org/abs/2406.11594>[paper]</a></li> <li>[Arxiv 24.06] <strong>Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks</strong><a href=https://arxiv.org/abs/2406.04612>[paper]</a></li> <li>[Arxiv 24.05] <strong>SIG: Efficient Self-Interpretable Graph Neural Network for Continuous-time Dynamic Graphs</strong><a href=https://arxiv.org/abs/2405.19062>[paper]</a></li> <li>[Arxiv 24.06] <strong>Towards Understanding Sensitive and Decisive Patterns in Explainable AI: A Case Study of Model Interpretation in Geometric Deep Learning</strong><a href=https://arxiv.org/abs/2407.00849>[paper]</a></li> <li>[Arxiv 24.06] <strong>Explainable Graph Neural Networks Under Fire</strong> <a href=https://arxiv.org/abs/2406.06417>[paper]</a></li> <li>[Arxiv 24.06] <strong>Explainable AI Security: Exploring Robustness of Graph Neural Networks to Adversarial Attacks</strong> <a href=https://arxiv.org/abs/2406.13920>[paper]</a></li> <li>[Arxiv 24.06] <strong>Perks and Pitfalls of Faithfulness in Regular, Self-Explainable and Domain Invariant GNNs</strong> <a href=https://arxiv.org/abs/2406.15156>[paper]</a></li> <li>[Arxiv 24.05] <strong>Utilizing Description Logics for Global Explanations of Heterogeneous Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2405.12654>[paper]</a></li> <li>[Arxiv 24.05] <strong>MAGE: Model-Level Graph Neural Networks Explanations via Motif-based Graph Generation</strong> <a href=https://arxiv.org/abs/2405.12519>[paper]</a></li> <li>[Arxiv 24.05] <strong>Detecting Complex Multi-step Attacks with Explainable Graph Neural Network</strong> <a href=https://arxiv.org/abs/2405.11335>[paper]</a></li> <li>[Arxiv 24.05] <strong>SynHING: Synthetic Heterogeneous Information Network Generation for Graph Learning and Explanation</strong><a href=https://arxiv.org/abs/2401.04133>[paper]</a></li> <li>[Preprint 24.05] <strong>Explainable Graph Neural Networks: An Application to Open Statistics Knowledge Graphs for Estimating House Prices</strong> <a href=https://www.preprints.org/manuscript/202405.0037/v1>[paper]</a></li> <li>[Arxiv 24.04] <strong>Superior Polymeric Gas Separation Membrane Designed by Explainable Graph Machine Learning</strong> <a href=https://arxiv.org/abs/2404.10903>[paper]</a></li> <li>[Arxiv 24.04] <strong>Improving the interpretability of GNN predictions through conformal-based graph sparsification</strong> <a href=https://arxiv.org/abs/2404.12356>[paper]</a></li> <li>[Arxiv 24.03] <strong>GreeDy and CoDy: Counterfactual Explainers for Dynamic Graph</strong><a href=https://arxiv.org/abs/2403.16846>[paper]</a></li> <li>[Arxiv 24.03] <strong>Explainable Graph Neural Networks for Observation Impact Analysis in Atmospheric State Estimation</strong><a href=https://arxiv.org/abs/2403.17384>[paper]</a></li> <li>[Arxiv 24.03] <strong>Securing GNNs: Explanation-Based Identification of Backdoored Training Graphs</strong><a href=https://arxiv.org/abs/2403.18136>[paper]</a></li> <li>[Arixv 24.03] <strong>Iterative Graph Neural Network Enhancement via Frequent Subgraph Mining of Explanations</strong><a href=https://arxiv.org/abs/2403.07849>[paper]</a></li> <li>[Arxiv 24.03] <strong>Explainable Graph Neural Networks for Observation Impact Analysis in Atmospheric State Estimation</strong><a href=https://arxiv.org/abs/2403.17384>[paper]</a></li> <li>[Arxiv 24.02] <strong>PAC Learnability under Explanation-Preserving Graph Perturbations</strong><a href=https://arxiv.org/abs/2402.05039>[paper]</a></li> <li>[Arxiv 24.02] <strong>Explainable Global Wildfire Prediction Models using Graph Neural Networks</strong><a href=https://arxiv.org/abs/2402.07152>[paper]</a></li> <li>[Arxiv 24.02] <strong>Incorporating Retrieval-based Causal Learning with Information Bottlenecks for Interpretable Graph Neural Networks</strong><a href=https://arxiv.org/abs/2402.04710>[paper]</a></li> <li>[Arxiv 24.01] <strong>On Discprecncies between Perturbation Evaluations of Graph Neural Network Attributions</strong><a href=https://arxiv.org/abs/2401.00633>[paper]</a></li> <li>[ASP=DAC 24] <strong>LIPSTICK: Corruptibility-Aware and Explainable Graph Neural Network-based Oracle-Less Attack on Logic Locking</strong><a href=https://arxiv.org/abs/2402.04235>[paper]</a></li> <li>[Biorxiv 24] <strong>Community-aware explanations in knowledge graphs with XP-GNN</strong><a href=https://www.biorxiv.org/content/10.1101/2024.01.21.576302v1.abstract>[paper]</a></li> <li>[ISCV 24] <strong>Adaptive Subgraph Feature Extraction for Explainable Multi-Modal Learning</strong><a href=https://ieeexplore.ieee.org/document/10620106/ >[paper]</a></li> <li>[IJCNN] <strong>Explanations for Graph Neural Networks using A Game-theoretic Value</strong><a href=https://ieeexplore.ieee.org/document/10650495>[paper]</a></li> <li>[Neurocomputing] <strong>GeoExplainer: Interpreting Graph Convolutional Networks with geometric masking</strong><a href=https://www.sciencedirect.com/science/article/abs/pii/S0925231224011640?via%3Dihub>[paper]</a></li> <li>[Technologies] <strong>Explainable Graph Neural Networks: An Application to Open Statistics Knowledge Graphs for Estimating House Prices</strong><a href=https://www.mdpi.com/2227-7080/12/8/128>[paper]</a></li> <li>[Reliab. Eng. Syst. Saf.] <strong>Causal intervention graph neural network for fault diagnosis of complex industrial processes</strong><a href=https://ieeexplore.ieee.org/document/10620106/ >[paper]</a></li> <li>[Frontiers in big data] <strong>Global explanation supervision for Graph Neural Networks</strong><a href=https://www.semanticscholar.org/reader/b6d6dda72e1d31e4b05e59909128cfccf4a835fb>[paper]</a></li> <li>[Information and Software Technology] <strong>Graph-based explainable vulnerability prediction</strong><a href=https://www.sciencedirect.com/science/article/pii/S095058492400171X?via%3Dihub>[paper]</a></li> <li>[Information Systems] <strong>Heterogeneous graph neural networks for fraud detection and explanation in supply chain finance</strong><a href=https://www.sciencedirect.com/science/article/abs/pii/S0306437923001710?via%3Dihub>[paper]</a></li> <li>[Information Procs. &amp; Mana.] <strong>Towards explaining graph neural networks via preserving prediction ranking and structural dependency</strong><a href=https://www.sciencedirect.com/science/article/pii/S0306457323003084>[paper]</a></li> <li>[Applied Energy] <strong>Explainable Spatio-Temporal Graph Neural Networks for multi-site photovoltaic energy production</strong> <a href=https://www.sciencedirect.com/science/article/pii/S0306261923015155>[paper]</a></li> <li>[PAKDD 24] <strong>Random Mask Perturbation Based Explainable Method of Graph Neural Networks</strong> <a href=https://link.springer.com/chapter/10.1007/978-981-97-2259-4_2>[paper]</a></li> <li>[Computational Materials Science] <strong>Graph isomorphism network for materials property prediction along with explainability analysis</strong><a href=https://www.sciencedirect.com/science/article/pii/S0927025623006134>[paper]</a></li> <li>[NN 24] <strong>Explanatory subgraph attacks against Graph Neural Networks</strong><a href=https://www.sciencedirect.com/science/article/pii/S0893608024000030>[paper]</a></li> <li>[NN 24] <strong>GRAM: An interpretable approach for graph anomaly detection using gradient attention maps</strong><a href=https://www.sciencedirect.com/science/article/pii/S0893608024003873>[paper]</a></li> <li>[Neural Networks 24] <strong>CI-GNN: A Granger Causality-Inspired Graph Neural Network for Interpretable Brain Network-Based Psychiatric Diagnosis</strong> <a href=https://arxiv.org/abs/2301.01642>[paper]</a></li> <li>[NeuroImage 24] <strong>BPI-GNN: Interpretable brain network-based psychiatric diagnosis and subtyping</strong><a href=https://www.sciencedirect.com/science/article/pii/S1053811924000892>[paper]</a></li> <li>[PAKDD 24] <strong>Toward Interpretable Graph Classification via Concept-Focused Structural Correspondence</strong> <a href=https://link.springer.com/chapter/10.1007/978-981-97-2650-9_2>[paper]</a></li> <li>[MedRxiv 24] <strong>An Interpretable Population Graph Network to Identify Rapid Progression of Alzheimer’s Disease Using UK Biobank</strong><a href=https://www.medrxiv.org/content/10.1101/2024.03.27.24304966v1>[paper]</a></li> <li>[IEEE TDSC 24] <strong>TrustGuard: GNN-based Robust and Explainable Trust Evaluation with Dynamicity Support</strong> <a href=https://arxiv.org/pdf/2306.13339.pdf>[paper]</a></li> <li>[IEEE Transactions] <strong>IEEE Transactions on Computational Social Systems</strong><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6570650">[paper]</a></li> <li>[Journal of Physics] <strong>Explainer on GNN-based segmentation networks</strong><a href=https://iopscience.iop.org/article/10.1088/1742-6596/2711/1/012009/meta>[paper]</a></li> <li>[Energy and AI] <strong>Electricity demand forecasting at distribution and household levels using explainable causal graph neural network</strong> <a href=https://www.sciencedirect.com/science/article/pii/S266654682400034X>[paper]</a></li> </ol> <h2 id=year-2023>Year 2023<a class=headerlink href=#year-2023 title="Permanent link">&para;</a></h2> <ol> <li>[NeurIPS 23] <strong>Interpretable Graph Networks Formulate Universal Algebra Conjectures</strong><a href=https://arxiv.org/abs/2307.11688>[paper]</a></li> <li>[NeurIPS 23] <strong>SAME: Uncovering GNN Black Box with Structure-aware Shapley-based Multipiece Explanation</strong> <a href="https://openreview.net/forum?id=kBBsj9KRgh">[paper]</a></li> <li>[NeurIPS 23] <strong>Train Once and Explain Everywhere: Pre-training Interpretable Graph Neural Networks</strong><a href="https://openreview.net/forum?id=enfx8HM4Rp">[paper]</a></li> <li>[NeurIPS 23] <strong>D4Explainer: In-distribution Explanations of Graph Neural Network via Discrete Denoising Diffusion</strong> <a href=https://arxiv.org/abs/2310.19321>[paper]</a></li> <li>[NeurIPS 23] <strong>TempME: Towards the Explainability of Temporal Graph Neural Networks via Motif Discovery</strong> <a href=https://arxiv.org/abs/2310.19324>[paper]</a></li> <li>[NeurIPS 23] <strong>V-InFoR: A Robust Graph Neural Networks Explainer for Structurally Corrupted Graphs</strong> <a href="https://openreview.net/forum?id=CtXXOaxDw7">[paper]</a></li> <li>[NeurIPS 23] <strong>Towards Self-Interpretable Graph-Level Anomaly Detection</strong> <a href=https://arxiv.org/abs/2310.16520>[paper]</a></li> <li>[NeurIPS 23] <strong>Evaluating Post-hoc Explanations for Graph Neural Networks via Robustness Analysis</strong> <a href="https://openreview.net/forum?id=eD534mPhAg">[paper]</a></li> <li>[NeurIPS 23] <strong>Interpretable Prototype-based Graph Information Bottleneck</strong> <a href=https://arxiv.org/abs/2310.19906>[paper]</a></li> <li>[ICML 23] <strong>Rethinking Explaining Graph Neural Networks via Non-parametric Subgraph Matching</strong> <a href="https://openreview.net/forum?id=MocsSAUKlk">[paper]</a></li> <li>[ICML 23] <strong>Relevant Walk Search for Explaining Graph Neural Networks</strong> <a href="https://openreview.net/forum?id=BDYIci7bVs">[paper]</a></li> <li>[ICML 23] <strong>Towards Understanding the Generalization of Graph Neural Networks</strong> <a href="https://openreview.net/pdf?id=BhMyLk0YNy">[paper]</a></li> <li>[ICLR 23] <strong>GNNInterpreter: A Probabilistic Generative Model-Level Explanation for Graph Neural Networks</strong> <a href=https://arxiv.org/pdf/2209.07924.pdf>[paper]</a></li> <li>[ICLR 23] <strong>Global Explainability of GNNs via Logic Combination of Learned Concepts</strong> <a href="https://openreview.net/forum?id=OTbRTIY4YS">[paper]</a></li> <li>[ICLR 23] <strong>Explaining Temporal Graph Models through an Explorer-Navigator Framework</strong> <a href="https://openreview.net/forum?id=BR_ZhvcYbGJ">[paper]</a></li> <li>[ICLR 23] <strong>DAG Matters! GFlowNets Enhanced Explainer for Graph Neural Networks</strong> <a href="https://openreview.net/forum?id=jgmuRzM-sb6">[paper]</a></li> <li>[ICLR 23] <strong>Interpretable Geometric Deep Learning via Learnable Randomness Injection</strong> <a href=https://arxiv.org/abs/2210.16966>[paper]</a></li> <li>[ICLR 23] <strong>A Differential Geometric View and Explainability of GNN on Evolving Graphs</strong> <a href="https://openreview.net/forum?id=lRdhvzMpVYV">[paper]</a></li> <li>[KDD 23] <strong>MixupExplainer: Generalizing Explanations for Graph Neural Networks with Data Augmentation</strong> <a href=https://arxiv.org/abs/2307.07832>[paper]</a></li> <li>[KDD 23] <strong>Counterfactual Learning on Heterogeneous Graphs with Greedy Perturbation</strong> <a href=https://repository.kaust.edu.sa/handle/10754/693484>[paper]</a></li> <li>[KDD 23] <strong>Empower Post-hoc Graph Explanations with Information Bottleneck: A Pre-training and Fine-tuning Perspective</strong><a href=https://dl.acm.org/doi/10.1145/3580305.3599330>[paper]</a></li> <li>[KDD 23] <strong>Less is More: SlimG for Accurate, Robust, and Interpretable Graph Mining.</strong><a href=https://dl.acm.org/doi/10.1145/3580305.3599413>[paper]</a></li> <li>[KDD 23] <strong>Shift-Robust Molecular Relational Learning with Causal Substructure</strong> <a href=https://dl.acm.org/doi/abs/10.1145/3580305.3599437>[paper]</a></li> <li>[AAAI 23] <strong>Global Concept-Based Interpretability for Graph Neural Networks via Neuron Analysis</strong> <a href=https://arxiv.org/abs/2208.10609>[paper]</a></li> <li>[AAAI 23] <strong>On the Limit of Explaining Black-box Temporal Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2212.00952>[paper]</a></li> <li>[AAAI 23] <strong>Towards Fine-Grained Explainability for Heterogeneous Graph Neural Network</strong> <a href=https://ojs.aaai.org/index.php/AAAI/article/download/26040/25812>[paper]</a></li> <li>[AAAI 23] <strong>Interpretable Chirality-Aware Graph Neural Network for Quantitative Structure Activity Relationship Modeling in Drug Discovery</strong> <a href="https://openreview.net/forum?id=W2OStztdMhc">[paper]</a></li> <li>[VLDB 23] <strong>HENCE-X: Toward Heterogeneity-agnostic Multi-level Explainability for Deep Graph Networks</strong> <a href=https://www.vldb.org/pvldb/vol16/p2990-lv.pdf>[paper]</a></li> <li>[VLDB 23] <strong>On Data-Aware Global Explainability of Graph Neural Networks</strong> <a href=https://www.vldb.org/pvldb/vol16/p3447-lv.pdf>[paper]</a></li> <li>[AISTATS 23] <strong>Distill n' Explain: explaining graph neural networks using simple surrogates</strong> <a href=https://arxiv.org/abs/2303.10139>[Paper]</a></li> <li>[AISTATS 23] <strong>Probing Graph Representations</strong> <a href=https://proceedings.mlr.press/v206/akhondzadeh23a/akhondzadeh23a.pdf>[paper]</a></li> <li>[ICDE 23] <strong>INGREX: An Interactive Explanation Framework for Graph Neural Networks</strong><a href=https://arxiv.org/pdf/2211.01548.pdf>[paper]</a></li> <li>[ICDE 23] <strong>Jointly Attacking Graph Neural Network and its Explanations</strong> <a href=https://arxiv.org/pdf/2108.03388.pdf>[paper]</a></li> <li>[WWW 23]<strong>PaGE-Link: Path-based Graph Neural Network Explanation for Heterogeneous Link Prediction</strong> <a href=https://arxiv.org/pdf/2302.12465.pdf>[paper]</a></li> <li>[ICDM 23] <strong>Limitations of Perturbation-based Explanation Methods for Temporal Graph Neural Networks</strong></li> <li>[ICDM 23] <strong>Interpretable Subgraph Feature Extraction for Hyperlink Prediction</strong><a href=https://www.researchgate.net/publication/378000024_Interpretable_Subgraph_Feature_Extraction_for_Hyperlink_Prediction>[paper]</a></li> <li>[WSDM 23]<strong>Interpretable Research Interest Shift Detection with Temporal Heterogeneous Graphs</strong> <a href=https://dl.acm.org/doi/pdf/10.1145/3539597.3570453>[paper]</a></li> <li>[WSDM 23]<strong>Cooperative Explanations of Graph Neural Networks</strong> <a href=https://dl.acm.org/doi/pdf/10.1145/3539597.3570378>[paper]</a></li> <li>[WSDM 23]<strong>Towards Faithful and Consistent Explanations for Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2205.13733>[paper]</a></li> <li>[WSDM 23] <strong>Global Counterfactual Explainer for Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2210.11695>[paper]</a></li> <li>[CIKM 23] <strong>Explainable Spatio-Temporal Graph Neural Networks</strong> <a href=https://dl.acm.org/doi/abs/10.1145/3583780.3614871>[paper]</a></li> <li>[CIKM 23] <strong>DuoGAT: Dual Time-oriented Graph Attention Networks for Accurate, Efficient and Explainable Anomaly Detection on Time-series.</strong> <a href=https://dl.acm.org/doi/abs/10.1145/3583780.3614857>[paper]</a></li> <li>[CIKM 23] <strong>Heterogeneous Temporal Graph Neural Network Explainer</strong> <a href=https://dl.acm.org/doi/abs/10.1145/3583780.3614909>[paper]</a></li> <li>[CIKM 23] <strong>ACGAN-GNNExplainer: Auxiliary Conditional Generative Explainer for Graph Neural Networks</strong><a href>[paper]</a></li> <li>[CIKM 23] <strong>KG4Ex: An Explainable Knowledge Graph-Based Approach for Exercise Recommendation</strong> <a href=https://dl.acm.org/doi/10.1145/3583780.3614943>[paper]</a></li> <li>[ECML-PKDD 23] <strong>ENGAGE: Explanation Guided Data Augmentation for Graph Representation Learning</strong> <a href=https://arxiv.org/abs/2307.01053>[paper]</a></li> <li>[TPAMI 23] <strong>FlowX: Towards Explainable Graph Neural Networks via Message Flows</strong> <a href=https://arxiv.org/abs/2206.12987>[paper]</a></li> <li>[TAI] <strong>Prototype-based interpretable graph neural networks.</strong> <a href=https://ieeexplore.ieee.org/document/9953541>[paper]</a></li> <li>[TKDE 23] <strong>Counterfactual Graph Learning for Anomaly Detection on Attributed Networks</strong> <a href=https://ieeexplore.ieee.org/document/10056298>[paper]</a></li> <li>[Scientific Data 23 ] <strong>Evaluating explainability for graph neural networks</strong> <a href=https://www.nature.com/articles/s41597-023-01974-x>[paper]</a></li> <li>[Nature Communications 23] <strong>Chemistry-intuitive explanation of graph neural networks for molecular property prediction with substructure masking</strong> <a href=https://www.nature.com/articles/s41467-023-38192-3>[paper]</a></li> <li>[ACM Computing Surveys 23] <strong>A Survey on Graph Counterfactual Explanations: Definitions, Methods, Evaluation</strong> <a href=https://arxiv.org/abs/2210.12089>[paper]</a></li> <li>[TIST 23] <strong>Faithful and Consistent Graph Neural Network Explanations with Rationale Alignment</strong> <a href=https://arxiv.org/abs/2301.02791>[paper]</a></li> <li>[Openreview 23] <strong>STExplainer: Global Explainability of GNNs via Frequent SubTree Mining</strong> <a href="https://openreview.net/forum?id=HgSfV6sGIn">[paper]</a></li> <li>[GLFrontiers 23] <strong>Everybody Needs a Little HELP: Explaining Graphs via Hierarchical Concepts</strong> <a href="https://openreview.net/forum?id=wrqAn3AJA1">[paper]</a></li> <li>[Openreview 23] <strong>Iterative Graph Neural Network Enhancement Using Explanations</strong> <a href="https://openreview.net/forum?id=qp0oVaFGm0">[paper]</a></li> <li>[Openreview 23] <strong>Interpretable and Convergent Graph Neural Network Layers at Scale</strong> <a href="https://openreview.net/forum?id=uYTaVRkKvz">[paper]</a></li> <li>[NeurIPS 2023 Workshop XAIA] <strong>GInX-Eval: Towards In-Distribution Evaluation of Graph Neural Networks Explanations</strong> <a href="https://openreview.net/forum?id=88MalncLgU">[paper]</a></li> <li>[NeurIPS 2023 Workshop XAIA] <strong>On the Consistency of GNN Explainability Methods</strong> <a href="https://openreview.net/forum?id=tiLZkab8TP">[paper]</a></li> <li>[Arxiv 23] <strong>Evaluating Neighbor Explainability for Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2311.08118>[paper]</a></li> <li>[Arxiv 23] <strong>DyExplainer: Explainable Dynamic Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2310.16375>[paper]</a></li> <li>[Arxiv 23] <strong>Explainability-Based Adversarial Attack on Graphs Through Edge Perturbation</strong><a href=https://arxiv.org/abs/2312.17301>[paper]</a></li> <li>[AICS 23] <strong>A subgraph interpretation generative model for knowledge graph link prediction based on uni-relation transformation</strong> <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12803/1280339/A-subgraph-interpretation-generative-model-for-knowledge-graph-link-prediction/10.1117/12.3009388.short?SSO=1">[paper]</a></li> <li>[GUT 23] <strong>Screening of normal endoscopic large bowel biopsies with interpretable graph learning: a retrospective study</strong> <a href=https://gut.bmj.com/content/gutjnl/early/2023/05/11/gutjnl-2023-329512.full.pdf>[paper]</a></li> <li>[PR 2023] <strong>Towards self-explainable graph convolutional neural network with frequency adaptive inception</strong> <a href=https://www.sciencedirect.com/science/article/abs/pii/S0031320323006891>[paper]</a></li> <li>[MLG 2023] <strong>Understanding how explainers work in graph neural networks</strong> <a href=https://mlg-europe.github.io/papers/241.pdf>[paper]</a></li> <li>[MLG 2023] <strong>Graph Model Explainer Tool</strong> <a href=https://www.mlgworkshop.org/2023/papers/MLG__KDD_2023_paper_5.pdf>[paper]</a></li> <li>[Information Science 23] <strong>Robust explanations for graph neural network with neuron explanation component</strong> <a href=https://www.sciencedirect.com/science/article/pii/S0020025523013701>[paper]</a></li> <li>[Recsys 23] <strong>Explainable Graph Neural Network Recommenders; Challenges and Opportunities</strong> <a href=https://dl.acm.org/doi/abs/10.1145/3604915.3608875>[paper]</a></li> <li>[xAI 23] <strong>Counterfactual Explanations for Graph Classification Through the Lenses of Density</strong> <a href=https://arxiv.org/abs/2307.14849>[paper]</a></li> <li>[XAI 23] <strong>Evaluating Link Prediction Explanations for Graph Neural Networks</strong> [[paper]](<a href=https://arxiv.org/abs/2308.01682>https://arxiv.org/abs/2308.01682</a></li> <li>[xAI 23] <strong>XInsight: Revealing Model Insights for GNNs with Flow-based Explanations</strong> <a href=https://arxiv.org/pdf/2306.04791.pdf>[paper]</a></li> <li>[xAI 23] <strong>Quantifying the Intrinsic Usefulness of Attributional Explanations for Graph Neural Networks with Artificial Simulatability Studies</strong> <a href=https://arxiv.org/abs/2305.15961>[paper]</a></li> <li>[xAI 23] <strong>MEGAN: Multi Explanation Graph Attention Network</strong> <a href="https://openreview.net/forum?id=H6LVUiHzYDE">[paper]</a></li> <li>[XKDD 23] <strong>Game Theoretic Explanations for Graph Neural Networks</strong> <a href=http://xkdd2023.isti.cnr.it/papers/424.pdf>[paper]</a></li> <li>[XKDD 23] <strong>From Black Box to Glass Box: Evaluating Faithfulness of Process Predictions with GCNNs</strong> <a href=http://xkdd2023.isti.cnr.it/papers/425.pdf>[paper]</a></li> <li>[IJCNN 23] <strong>MEGA: Explaining Graph Neural Networks with Network Motifs</strong> <a href=https://doi.org/10.1109/IJCNN54540.2023.10191684>[paper]</a></li> <li>[LOG Poster 23] <strong>On the Robustness of Post-hoc GNN Explainers to Label Noise</strong> <a href=https://arxiv.org/abs/2309.01706>[paper]</a></li> <li>[LOG Poster 23] <strong>How Faithful are Self-Explainable GNNs?</strong> <a href=https://arxiv.org/abs/2308.15096>[paper]</a></li> <li>[LOG Poster 23] <strong>Explaining Link Predictions in Knowledge Graph Embedding Models with Influential Examples</strong> <a href=https://arxiv.org/abs/2212.02651>[paper]</a></li> <li>[Bioriv 23] <strong>Building explainable graph neural network by sparse learning for the drug-protein binding prediction</strong> <a href=https://www.biorxiv.org/content/10.1101/2023.08.28.555203v1.abstract>[paper]</a></li> <li>[ICAID 2023] <strong>Explanations for Graph Neural Networks via Layer Analysis.</strong> <a href=https://www.atlantis-press.com/proceedings/icaid-23/125990065>[paper]</a></li> <li>[ECAI 23] <strong>XGBD: Explanation-Guided Graph Backdoor Detection</strong> <a href=https://arxiv.org/abs/2308.04406>[paper]</a></li> <li>[IEEE Transactions on Consumer Electronics 23] <strong>Human Pose Prediction Using Interpretable Graph Convolutional Network for Smart Home</strong> <a href=https://arxiv.org/abs/2308.04406>[paper]</a></li> <li>[KBS 23] <strong>KE-X: Towards subgraph explanations of knowledge graph embedding based on knowledge information gain</strong> <a href="http://sites.computer.org/debull/A23june/A23JUNE-CD.pdf#page=64">[paper]</a></li> <li>[ICML workshop 23] <strong>Generating Global Factual and Counterfactual Explainer for Molecule under Domain Constraints</strong> <a href="https://openreview.net/forum?id=qElXYQqxQh">[paper]</a></li> <li>[Thesis 23] <strong>Developing interpretable graph neural networks for high dimensional feature spaces</strong> <a href=https://pub.tik.ee.ethz.ch/students/2022-HS/BA-2022-43.pdf>[paper]</a></li> <li>[Thesis 23] <strong>Evaluation of Explainability Methods on Single-Cell Classification Tasks Using Graph Neural Networks</strong> <a href=https://www.semanticscholar.org/paper/Evaluation-of-Explainability-Methods-on-Single-Cell-Singh-Kobayashi/85f4aba430387a337ec3a4b2aa39bfc7361dea1f>[paper]</a></li> <li>[Arxiv 23] <strong>On the Interplay of Subset Selection and Informed Graph Neural Networks</strong> <a href=https://www.semanticscholar.org/paper/On-the-Interplay-of-Subset-Selection-and-Informed-Breustedt-Climaco/2c76331ac1676ed7fdd51b8cd744765628e0a181>[paper]</a></li> <li>[ISSTA23] <strong>Interpreters for GNN-Based Vulnerability Detection: Are We There Yet?</strong> <a href=https://www.semanticscholar.org/paper/Interpreters-for-GNN-Based-Vulnerability-Detection%3A-Hu-Wang/6bb9c86483f212a631324ba9b47c344d419a428a>[paper]</a></li> <li>[ICECAI23] <strong>Improved GraphSVX for GNN Explanations Based on Cross Entropy</strong> <a href=https://www.semanticscholar.org/paper/Improved-GraphSVX-for-GNN-Explanations-Based-on-Yu-Liang/b01c4f2c4d54723b590a828d4e1b4cdbfea5dad4>[paper]</a></li> <li>[ICRA Workshop 23] <strong>Towards Semantic Interpretation and Validation of Graph Attention-based Explanations</strong> <a href="https://openreview.net/forum?id=ymyQeqatQqQ">[paper]</a></li> <li>[Arxiv 23] <strong>Graph Neural Network based Log Anomaly Detection and Explanation</strong> <a href=https://arxiv.org/abs/2307.00527>[paper]</a></li> <li>[Arxiv 23] <strong>Interpreting GNN-based IDS Detections Using Provenance Graph Structural Features</strong> <a href=https://arxiv.org/abs/2306.00934>[paper]</a></li> <li>[Thesis 23] <strong>Interpretability of Graphical Models</strong> <a href="https://search.proquest.com/openview/1e61b389a59936e319974be0e3fd1af5/1?pq-origsite=gscholar&cbl=18750&diss=y">[paper]</a></li> <li>[Bioengineering 2023] <strong>Personalized Explanations for Early Diagnosis of Alzheimer's Disease Using Explainable Graph Neural Networks with Population Graphs</strong> <a href=https://www.mdpi.com/2306-5354/10/6/701>[paper]</a></li> <li>[BDSC 2023] <strong>MDC: An Interpretable GNNs Method Based on Node Motif Degree and Graph Diffusion Convolution</strong> [[paper]] (<a href=https://link.springer.com/chapter/10.1007/978-981-99-3925-1_24>https://link.springer.com/chapter/10.1007/978-981-99-3925-1_24</a>)</li> <li>[Information Science 2023] <strong>Explainability techniques applied to road traffic forecasting using Graph Neural Network models</strong> <a href=https://www.sciencedirect.com/science/article/pii/S0020025523009052>[paper]</a></li> <li>[Arxiv 23] <strong>Efficient GNN Explanation via Learning Removal-based Attribution</strong> <a href=https://arxiv.org/abs/2306.05760>[paper]</a></li> <li>[Arxiv 23] <strong>Empowering Counterfactual Reasoning over Graph Neural Networks through Inductivity</strong> <a href=https://arxiv.org/pdf/2306.04835.pdf>[paper]</a></li> <li>[ICLR Tiny 23] <strong>Message-passing selection: Towards interpretable GNNs for graph classification</strong> <a href="https://openreview.net/forum?id=99Go96dla5y">[paper]</a></li> <li>[ICLR Tiny 23] <strong>Revisiting CounteRGAN for Counterfactual Explainability of Graphs</strong> <a href="https://openreview.net/forum?id=d0m0Rl15q3g">[paper]</a></li> <li>[MICCAI Workshop 23] <strong>IA-GCN: Interpretable Attention based Graph Convolutional Network for Disease prediction</strong> <a href=https://arxiv.org/pdf/2103.15587.pdf>[paper]</a></li> <li>[Arxiv 23] <strong>Robust Ante-hoc Graph Explainer using Bilevel Optimization</strong> <a href=https://arxiv.org/abs/2305.15745>[paper]</a></li> <li>[GRADES &amp; NDA'23] <strong>A Demonstration of Interpretability Methods for Graph Neural Networks</strong> <a href=https://homes.cs.aau.dk/~Arijit/Papers/gInterpreter_GRADES_NDA23.pdf>[paper]</a></li> <li>[Arxiv 23] <strong>Self-Explainable Graph Neural Networks for Link Prediction</strong> <a href=https://arxiv.org/abs/2305.12578>[paper]</a></li> <li>[ChemRxiv 23] <strong>Interpreting Graph Neural Networks with Myerson Values for Cheminformatics Approaches</strong> <a href=https://chemrxiv.org/engage/chemrxiv/article-details/6456c89707c3f0293753101d>[paper]</a></li> <li>[Neural Networks 23] <strong>Generating Post-hoc Explanations for Skip-gram-based Node Embeddings by Identifying Important Nodes with Bridgeness</strong> <a href=https://arxiv.org/abs/2304.12036>[paper]</a></li> <li>[ICASSP 23] <strong>Towards a More Stable and General Subgraph Information Bottleneck</strong> <a href=https://ieeexplore.ieee.org/document/10094812>[paper]</a></li> <li>[ESANN 23] <strong>Combining Stochastic Explainers and Subgraph Neural Networks can Increase Expressivity and Interpretability</strong> <a href=https://arxiv.org/abs/2304.07152>[Paper]</a></li> <li>[IEEE Access] <strong>Generating Real-Time Explanations for GNNs via Multiple Specialty Learners and Online Knowledge Distillation</strong> <a href=https://ieeexplore.ieee.org/document/10107968>[Paper]</a></li> <li>[IEEE Access] <strong>Providing Post-Hoc Explanation for Node Representation Learning Models Through Inductive Conformal Predictions</strong> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10003193&tag=1">[paper]</a></li> <li>[Journal of Software 23] <strong>A Slice-level vulnerability detection and interpretation method based on graph neural network</strong> <a href=http://www.jos.org.cn/josen/article/abstract/mr008>[paper]</a></li> <li>[Automation in Construction 23] <strong>Learning from explainable data-driven tunneling graphs: A spatio-temporal graph convolutional network for clogging detection</strong> <a href=https://www.sciencedirect.com/science/article/pii/S0926580523000018>[paper]</a></li> <li>[Briefings in Bioinformatics] <strong>Predicting molecular properties based on the interpretable graph neural network with multistep focus mechanism</strong> <a href=https://academic.oup.com/bib/advance-article/doi/10.1093/bib/bbac534/6918752>[paper]</a></li> <li>[Briefings in Bioinformatics] <strong>Identification of vital chemical information via visualization of graph neural networks</strong> <a href=https://academic.oup.com/bib/article/24/1/bbac577/6936421>[paper]</a></li> <li>[Bioinformatics 23] <strong>Explainable Multilayer Graph Neural Network for Cancer Gene Prediction</strong> <a href=https://arxiv.org/pdf/2301.08831.pdf>[paper]</a></li> <li>[ICLR Workshop 23] <strong>GCI: A Graph Concept Interpretation Framework</strong> <a href=https://arxiv.org/abs/2302.04899>[paper]</a></li> <li>[Arxiv 23] <strong>Structural Explanations for Graph Neural Networks using HSIC</strong> <a href=https://arxiv.org/abs/2302.02139>[paper]</a></li> <li>[Internet of Things 23] <strong>XG-BoT: An Explainable Deep Graph Neural Network for Botnet Detection and Forensics</strong> <a href=https://arxiv.org/abs/2207.09088>[paper]</a></li> <li>[JOS23] <strong>A Generic Explaining &amp; Locating Method for Malware Detection based on Graph Neural Networks</strong> <a href=https://www.jos.org.cn/josen/article/abstract/7123>[paper]</a></li> </ol> <h2 id=year-2022>Year 2022<a class=headerlink href=#year-2022 title="Permanent link">&para;</a></h2> <ol> <li>[NeurIPS 22] <strong>GStarX:Explaining Graph-level Predictions with Communication Structure-Aware Cooperative Games</strong> <a href="https://openreview.net/pdf?id=Qry8exovcNA">[paper]</a></li> <li>[NeurIPS 22] <strong>Debiasing Graph Neural Networks via Learning Disentangled Causal Substructure</strong> <a href=https://arxiv.org/abs/2209.14107>[paper]</a></li> <li>[NeurIPS 22] <strong>Task-Agnostic Graph Neural Explanations</strong> <a href="https://openreview.net/pdf?id=NQrx8EYMboO">[paper]</a></li> <li>[NeurIPS 22] <strong>CLEAR: Generative Counterfactual Explanations on Graphs</strong><a href=https://arxiv.org/abs/2210.08443>[paper]</a></li> <li>[ICML 22] <strong>Interpretable and Generalizable Graph Learning via Stochastic Attention Mechanism</strong> <a href=https://arxiv.org/abs/2201.12987v1>[paper]</a></li> <li>[ICLR 22] <strong>DEGREE: Decomposition Based Explanation for Graph Neural Networks</strong> <a href="https://openreview.net/pdf?id=Ve0Wth3ptT_">[paper]</a></li> <li>[ICLR 22] <strong>Explainable GNN-Based Models over Knowledge Graphs</strong> <a href="https://openreview.net/attachment?id=CrCvGNHAIrz&name=pdf">[paper]</a></li> <li>[ICLR 22] <strong>Discovering Invariant Rationales for Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2201.12872>[paper]</a></li> <li>[KDD 22] <strong>On Structural Explanation of Bias in Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2206.12104>[paper]</a></li> <li>[KDD 22] <strong>Causal Attention for Interpretable and Generalizable Graph Classification</strong> <a href=https://arxiv.org/abs/2112.15089>[paper]</a></li> <li>[CVPR 22] <strong>OrphicX: A Causality-Inspired Latent Variable Model for Interpreting Graph Neural Networks</strong> <a href=https://wanyu-lin.github.io/assets/publications/wanyu-cvpr2022.pdf>[paper]</a></li> <li>[CVPR 22] <strong>Improving Subgraph Recognition with Variational Graph Information Bottleneck</strong> <a href=https://arxiv.org/abs/2112.09899>[paper]</a></li> <li>[AISTATS 22] <strong>Probing GNN Explainers: A Rigorous Theoretical and Empirical Analysis of GNN Explanation Methods</strong> <a href=https://arxiv.org/abs/2106.09078>[paper]</a></li> <li>[AISTATS 22] <strong>CF-GNNExplainer: Counterfactual Explanations for Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2102.03322>[paper]</a></li> <li>[TPAMI 22] <strong>Differentially Private Graph Neural Networks for Whole-Graph Classification</strong> <a href=https://arxiv.org/abs/2212.03806>[paper]</a></li> <li>[TPAMI 22] <strong>Reinforced Causal Explainer for Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2204.11028>[paper]</a></li> <li>[VLDB 22] <strong>xFraud: Explainable Fraud Transaction Detection on Heterogeneous Graphs</strong> <a href=https://arxiv.org/pdf/2011.12193.pdf>[paper]</a></li> <li>[LOG 22]<strong>GraphFramEx: Towards Systematic Evaluation of Explainability Methods for Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2206.09677>[paper]</a></li> <li>[LOG 22] <strong>Towards Training GNNs using Explanation Directed Message Passing</strong> <a href=https://arxiv.org/abs/2211.16731>[paper]</a></li> <li>[The Webconf 22] <strong>Learning and Evaluating Graph Neural Network Explanations based on Counterfactual and Factual Reasoning</strong> <a href=https://arxiv.org/abs/2202.08816>[paper]</a></li> <li>[AAAI 22] <strong>Prototype-Based Explanations for Graph Neural Networks</strong> <a href=https://www.aaai.org/AAAI22Papers/SA-00396-ShinY.pdf>[paper]</a></li> <li>[AAAI 22] <strong>KerGNNs: Interpretable Graph Neural Networks with Graph Kernels</strong><a href=https://arxiv.org/pdf/2201.00491.pdf>[paper]</a></li> <li>[AAAI 22] <strong>ProtGNN: Towards Self-Explaining Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2112.00911>[paper]</a></li> <li>[IEEE Big Data 22] <strong>Trade less Accuracy for Fairness and Trade-off Explanation for GNN</strong> <a href=https://ieeexplore.ieee.org/abstract/document/10020318>[paper]</a></li> <li>[CIKM 22] <strong>GRETEL: A unified framework for Graph Counterfactual Explanation Evaluation</strong> <a href=https://arxiv.org/abs/2206.02957>[paper]</a></li> <li>[CIKM 22] <strong>GRETEL: Graph Counterfactual Explanation Evaluation Framework</strong><a href=https://dl.acm.org/doi/abs/10.1145/3511808.3557608>[paper]</a></li> <li>[CIKM 22] <strong>A Model-Centric Explainer for Graph Neural Network based Node Classification</strong> <a href=https://dl.acm.org/doi/10.1145/3511808.3557535>[paper]</a></li> <li>[IJCAI 22] <strong>What Does My GNN Really Capture? On Exploring Internal GNN Representations</strong> <a href=https://hal.archives-ouvertes.fr/hal-03700710/ >[paper]</a></li> <li>[ECML PKDD 22] <strong>Improving the quality of rule-based GNN explanations</strong> <a href=https://kdd.isti.cnr.it/xkdd2022/papers/XKDD_2022_paper_2436.pdf>[paper]</a></li> <li>[MICCAI 22] <strong>Interpretable Graph Neural Networks for Connectome-Based Brain Disorder Analysis</strong> <a href=https://arxiv.org/abs/2207.00813>[paper]</a></li> <li>[MICCAI 22] <strong>Sparse Interpretation of Graph Convolutional Networks for Multi-modal Diagnosis of Alzheimer’s Disease</strong> <a href=https://link.springer.com/chapter/10.1007/978-3-031-16452-1_45>[paper]</a></li> <li>[EuroS&amp;P 22] <strong>Illuminati: Towards Explaining Graph Neural Networks for Cybersecurity Analysis</strong> <a href="https://ieeexplore.ieee.org/abstract/document/9797387?casa_token=1AvRK3S4eJQAAAAA:8PXcOA8iU1ketRMdu6YVMBMcfZKjF7MIVujPpHTpjdc2O9r1cvUg8usfRiOYZ5Fe-MKJi4Y">[paper]</a></li> <li>[INFOCOM 22] <strong>Interpretability Evaluation of Botnet Detection Model based on Graph Neural Network</strong> <a href=https://ieeexplore.ieee.org/document/9798287>[paper]</a></li> <li>[GLOBECOM 22] <strong>Shapley Explainer - An Interpretation Method for GNNs Used in SDN</strong> <a href=https://ieeexplore.ieee.org/abstract/document/10001460>[paper]</a></li> <li>[GLOBECOM 22] <strong>An Explainer for Temporal Graph Neural Networks</strong> <a href=[https://arxiv.org/pdf/2209.00807.pdf]>[paper]</a></li> <li>[TKDE 22] <strong>Zorro: Valid, Sparse, and Stable Explanations in Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2105.08621>[paper]</a></li> <li>[TNNLS 22] <strong>Interpretable Graph Reservoir Computing With the Temporal Pattern Attention</strong> <a href=https://ieeexplore.ieee.org/abstract/document/10003110>[paper]</a></li> <li>[TNNLS22] <strong>A Meta-Learning Approach for Training Explainable Graph Neural Networks</strong> <a href=https://ieeexplore.ieee.org/abstract/document/9772740>[paper]</a></li> <li>[TNNLS 22] <strong>Explaining Deep Graph Networks via Input Perturbation</strong> <a href=https://pubmed.ncbi.nlm.nih.gov/35446771/ >[paper]</a></li> <li>[TNNLS 22] <strong>A Meta-Learning Approach for Training Explainable Graph Neural Network</strong> <a href=https://arxiv.org/pdf/2109.09426.pdf>[paper]</a></li> <li>[DMKD 22] <strong>On GNN explanability with activation patterns</strong> <a href=https://hal.archives-ouvertes.fr/hal-03367714/file/hal.pdf>[paper]</a></li> <li>[KBS 22] <strong>EGNN: Constructing explainable graph neural networks via knowledge distillation</strong> <a href=https://www.sciencedirect.com/science/article/pii/S0950705122001289?via%3Dihub>[paper]</a></li> <li>[XKDD 22] <strong>GREASE: Generate Factual and Counterfactual Explanations for GNN-based Recommendations</strong> <a href=https://arxiv.org/abs/2208.04222>[paper]</a></li> <li>[AI 22] <strong>Are Graph Neural Network Explainers Robust to Graph Noises?</strong> <a href=https://link.springer.com/chapter/10.1007/978-3-031-22695-3_12>[paper]</a></li> <li>[BRACIS 22] <strong>ConveXplainer for Graph Neural Networks</strong> <a href=https://link.springer.com/chapter/10.1007/978-3-031-21689-3_41>[paper]</a></li> <li>[GLB 22] <strong>An Explainable AI Library for Benchmarking Graph Explainers</strong> <a href=https://graph-learning-benchmarks.github.io/assets/papers/glb2022/An_Explainable_AI_Library_for_Benchmarking_Graph_Explainers.pdf>[paper]</a></li> <li>[DASFAA 22] <strong>On Global Explainability of Graph Neural Networks</strong> <a href=https://link.springer.com/chapter/10.1007/978-3-031-00123-9_52>[paper]</a></li> <li>[ISBI 22] <strong>Interpretable Graph Convolutional Network Of Multi-Modality Brain Imaging For Alzheimer’s Disease Diagnosis</strong> <a href="https://ieeexplore.ieee.org/abstract/document/9761449?casa_token=w3IlSZNlKwcAAAAA:Xvh04eK29bZtbkRq5Eg3jUZURS3qs1k3AA1bhnnN2kKWmIjBnh7alAiy98zBgsHFtvFQqV0IYA">[paper]</a></li> <li>[Bioinformatics] <strong>GNN-SubNet: disease subnetwork detection with explainable Graph Neural Networks</strong> <a href="https://academic.oup.com/bioinformatics/article/38/Supplement_2/ii120/6702000?login=false">[paper]</a></li> <li>[Medical Imaging 2022] <strong>Phenotype guided interpretable graph convolutional network analysis of fMRI data reveals changing brain connectivity during adolescence</strong> <a href=https://www.semanticscholar.org/paper/Phenotype-guided-interpretable-graph-convolutional-Orlichenko-Qu/d05adc7c772780be4b99a169441696017d49c6ed>[paper]</a></li> <li>[NeuroComputing 22] <strong>Perturb more, trap more: Understanding behaviors of graph neural networks</strong> <a href="https://www.sciencedirect.com/science/article/pii/S0925231222004404?casa_token=6KLu9elyyLMAAAAA:hM0eGpfSnLxF0V8fZJdoDE3hkalzK2yccBJl3X9KN-Btu_xDSZmmbORIfkYdK5rgjTr7MReeFxc">[paper]</a></li> <li>[DSN 22] <strong>CFGExplainer: Explaining Graph Neural Network-Based Malware Classification from Control Flow Graphs</strong> <a href=http://www.cs.binghamton.edu/~ghyan/papers/dsn22.pdf>[paper]</a></li> <li>[IEEE Access 22] <strong>Providing Node-level Local Explanation for node2vec through Reinforcement Learning</strong> <a href=https://mlog-workshop.github.io/papers/MLoG%20Providing%20Node-level%20Local%20Explanation%20for%20node2vec%20through%20Reinforcement%20Learning.pdf>[paper]</a></li> <li>[Patterns 22] <strong>Quantitative Evaluation of Explainable Graph Neural Networks for Molecular Property Prediction</strong> <a href=https://arxiv.org/pdf/2107.04119.pdf>[paper]</a></li> <li>[Arxiv 22] <strong>GRAPHSHAP: Motif-based Explanations for Black-box Graph Classifiers</strong> <a href=https://arxiv.org/abs/2202.08815>[paper]</a></li> <li>[IEEE Access 22] <strong>Providing Post-Hoc Explanation for Node Representation Learning Models Through Inductive Conformal Predictions</strong> <a href=https://ieeexplore.ieee.org/abstract/document/10003193>[paper]</a></li> <li>[IEEE 22] <strong>Explaining Graph Neural Networks With Topology-Aware Node Selection: Application in Air Quality Inference</strong> <a href=https://ieeexplore.ieee.org/document/9801665>[paper]</a></li> <li>[BioRxiv 22] <strong>GNN-SubNet: disease subnetwork detection with explainable Graph Neural Networks</strong> <a href=https://www.biorxiv.org/content/10.1101/2022.01.12.475995v1>[paper]</a></li> <li>[IEEE Robotics and Automation Letters 22] <strong>Efficient and Interpretable Robot Manipulation with Graph Neural Networks</strong> <a href=https://arxiv.org/pdf/2102.13177.pdf>[paper]</a></li> <li>[Arxiv 22] <strong>Deconfounding to Explanation Evaluation in Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2201.08802>[paper]</a></li> <li>[ICCPR 22] <strong>GANExplainer: GAN-based Graph Neural Networks Explainer</strong> <a href=https://arxiv.org/abs/2301.00012>[paper]</a></li> <li>[Arxiv 22] <strong>On the Probability of Necessity and Sufficiency of Explaining Graph Neural Networks: A Lower Bound Optimization Approach</strong> <a href=https://arxiv.org/abs/2212.07056>[paper]</a></li> <li>[Arxiv 22] <strong>Exploring Explainability Methods for Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2211.01770>[paper]</a></li> <li>[Arxiv 22] <strong>PAGE: Prototype-Based Model-Level Explanations for Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2210.17159>[paper]</a></li> <li>[Arxiv 22] <strong>Toward Multiple Specialty Learners for Explaining GNNs via Online Knowledge Distillation</strong> <a href=https://arxiv.org/abs/2210.11094>[paper]</a></li> <li>[Openreview 23] <strong>TGP: Explainable Temporal Graph Neural Networks for Personalized Recommendation</strong> <a href="https://openreview.net/forum?id=EGobBwPc1J-">[paper]</a></li> <li>[Openreview 23] <strong>On Regularization for Explaining Graph Neural Networks: An Information Theory Perspective</strong> <a href="https://openreview.net/forum?id=5rX7M4wa2R_">[paper]</a></li> <li>[Arxiv 22] <strong>L2XGNN: Learning to Explain Graph Neural Networks</strong> <a href=https://arxiv.org/pdf/2209.14402.pdf>[paper]</a></li> <li>[Arxiv 22] <strong>Towards Prototype-Based Self-Explainable Graph Neural Network</strong> <a href=https://arxiv.org/abs/2210.01974>[paper]</a></li> <li>[Arxiv 22] <strong>PGX: A Multi-level GNN Explanation Framework Based on Separate Knowledge Distillation Processes</strong> <a href=https://arxiv.org/abs/2208.03075>[paper]</a></li> <li>[Arxiv 22] <strong>Explainability in subgraphs-enhanced Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2209.07926>[paper]</a></li> <li>[Arxiv 22] <strong>Defending Against Backdoor Attack on Graph Neural Network by Explainability</strong> <a href=https://arxiv.org/pdf/2209.02902.pdf>[paper]</a></li> <li>[Arxiv 22] <strong>Explaining Dynamic Graph Neural Networks via Relevance Back-propagation</strong> <a href=https://arxiv.org/abs/2207.11175>[paper]</a></li> <li>[Arxiv 22] <strong>EiX-GNN : Concept-level eigencentrality explainer for graph neural networks</strong> <a href=https://arxiv.org/abs/2206.03491>[paper]</a></li> <li>[Arxiv 22] <strong>MotifExplainer: a Motif-based Graph Neural Network Explainer</strong> <a href=https://arxiv.org/abs/2202.00519>[paper]</a></li> <li>[Arxiv 22] <strong>Faithful Explanations for Deep Graph Models</strong> <a href=https://arxiv.org/abs/2205.11850>[paper]</a></li> <li>[Arxiv 22] <strong>Towards Explanation for Unsupervised Graph-Level Representation Learning</strong> <a href=https://arxiv.org/abs/2205.09934>[paper]</a></li> <li>[Arxiv 22] <strong>BAGEL: A Benchmark for Assessing Graph Neural Network Explanations</strong> <a href=https://arxiv.org/abs/2206.13983>[paper]</a></li> <li>[Arxiv 22] <strong>BrainIB: Interpretable Brain Network-based Psychiatric Diagnosis with Graph Information Bottleneck</strong> <a href=https://arxiv.org/abs/2205.03612>[paper]</a></li> <li>[Arxiv 22] <strong>A Comprehensive Survey on Trustworthy Graph Neural Networks: Privacy, Robustness, Fairness, and Explainability</strong> <a href=https://arxiv.org/abs/2204.08570>[paper]</a></li> <li>[Arxiv 22] <strong>Explainability in Graph Neural Networks: An Experimental Survey</strong> <a href=https://arxiv.org/abs/2203.09258>[paper]</a></li> <li>[IEEE TSIPN 22] <strong>Explainability and Graph Learning from Social Interactions</strong> <a href=https://arxiv.org/pdf/2203.07494.pdf>[paper]</a></li> <li>[Arxiv 22] <strong>Cognitive Explainers of Graph Neural Networks Based on Medical Concepts</strong> <a href=https://arxiv.org/abs/2201.07798>[paper]</a></li> </ol> <h2 id=year-2021>Year 2021<a class=headerlink href=#year-2021 title="Permanent link">&para;</a></h2> <ol> <li>[NeurIPS 21] <strong>SALKG: Learning From Knowledge Graph Explanations for Commonsense Reasoning</strong> <a href=https://arxiv.org/pdf/2104.08793.pdf>[paper]</a></li> <li>[NeurIPS 2021] <strong>Reinforcement Learning Enhanced Explainer for Graph Neural Networks</strong> <a href=http://recmind.cn/papers/explainer_nips21.pdf>[paper]</a></li> <li>[NeurIPS 2021] <strong>Towards Multi-Grained Explainability for Graph Neural Networks</strong> <a href=http://staff.ustc.edu.cn/~hexn/papers/nips21-explain-gnn.pdf>[paper]</a></li> <li>[NeurIPS 2021] <strong>Robust Counterfactual Explanations on Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2107.04086>[paper]</a></li> <li>[ICML 2021] <strong>On Explainability of Graph Neural Networks via Subgraph Explorations</strong><a href=https://arxiv.org/abs/2102.05152>[paper]</a></li> <li>[ICML 2021] <strong>Generative Causal Explanations for Graph Neural Networks</strong><a href=https://arxiv.org/abs/2104.06643>[paper]</a></li> <li>[ICML 2021] <strong>Improving Molecular Graph Neural Network Explainability with Orthonormalization and Induced Sparsity</strong><a href=https://arxiv.org/abs/2105.04854>[paper]</a></li> <li>[ICML 2021] <strong>Automated Graph Representation Learning with Hyperparameter Importance Explanation</strong><a href=http://proceedings.mlr.press/v139/wang21f/wang21f.pdf>[paper]</a></li> <li>[ICLR 2021] <strong>Interpreting Graph Neural Networks for NLP With Differentiable Edge Masking</strong><a href=https://arxiv.org/abs/2010.00577>[paper]</a></li> <li>[ICLR 2021] <strong>Graph Information Bottleneck for Subgraph Recognition</strong> <a href=https://arxiv.org/pdf/2010.05563.pdf>[paper]</a></li> <li>[KDD 2021] <strong>When Comparing to Ground Truth is Wrong: On Evaluating GNN Explanation Methods</strong><a href=https://dl.acm.org/doi/abs/10.1145/3447548.3467283>[paper]</a></li> <li>[KDD 2021] <strong>Counterfactual Graphs for Explainable Classification of Brain Networks</strong> <a href=https://arxiv.org/abs/2106.08640>[paper]</a></li> <li>[CVPR 2021] <strong>Quantifying Explainers of Graph Neural Networks in Computational Pathology</strong>.<a href=https://arxiv.org/pdf/2011.12646.pdf>[paper]</a></li> <li>[NAACL 2021] <strong>Counterfactual Supporting Facts Extraction for Explainable Medical Record Based Diagnosis with Graph Network</strong>. <a href=https://aclanthology.org/2021.naacl-main.156.pdf>[paper]</a></li> <li>[AAAI 2021] <strong>Motif-Driven Contrastive Learning of Graph Representations</strong> <a href=https://arxiv.org/pdf/2012.12533.pdf>[paper]</a></li> <li>[TPAMI 21] <strong>Higher-Order Explanations of Graph Neural Networks via Relevant Walks</strong> <a href=https://ieeexplore.ieee.org/document/9547794>[paper]</a></li> <li>[WWW 2021] <strong>Interpreting and Unifying Graph Neural Networks with An Optimization Framework</strong> <a href=https://arxiv.org/abs/2101.11859>[paper]</a></li> <li>[Genome medicine 21] <strong>Explaining decisions of Graph Convolutional Neural Networks: patient-specific molecular subnetworks responsible for metastasis prediction in breast cancer</strong> <a href=https://www.semanticscholar.org/paper/Explaining-decisions-of-Graph-Convolutional-Neural-Chereda-Bleckmann/49a4e339182b2b304304c8837b09ce3e0951a616>[paper]</a></li> <li>[IJCKG 21] <strong>Knowledge Graph Embedding in E-commerce Applications: Attentive Reasoning, Explanations, and Transferable Rules</strong> <a href=https://arxiv.org/abs/2112.08589>[paper]</a></li> <li>[RuleML+RR 21] <strong>Combining Sub-Symbolic and Symbolic Methods for Explainability</strong> <a href=https://arxiv.org/abs/2112.01844>[paper]</a></li> <li>[PAKDD 21] <strong>SCARLET: Explainable Attention based Graph Neural Network for Fake News spreader prediction</strong> <a href=https://arxiv.org/abs/2102.04627>[paper]</a></li> <li>[J. Chem. Inf. Model] <strong>Coloring Molecules with Explainable Artificial Intelligence for Preclinical Relevance Assessment</strong> <a href=https://pubs.acs.org/doi/abs/10.1021/acs.jcim.0c01344>[paper]</a></li> <li>[BioRxiv 21] <strong>APRILE: Exploring the Molecular Mechanisms of Drug Side Effects with Explainable Graph Neural Networks</strong> <a href=https://www.biorxiv.org/content/10.1101/2021.07.02.450937v2.abstract>[paper]</a></li> <li>[ISM 21] <strong>Edge-Level Explanations for Graph Neural Networks by Extending Explainability Methods for Convolutional Neural Networks</strong> <a href=https://arxiv.org/pdf/2111.00722.pdf>[paper]</a></li> <li>[Arxiv 21] <strong>Towards the Explanation of Graph Neural Networks in Digital Pathology with Information Flows</strong> <a href=https://arxiv.org/abs/2112.09895>[paper]</a></li> <li>[Arxiv 21] <strong>SEEN: Sharpening Explanations for Graph Neural Networks using Explanations from Neighborhoods</strong> <a href=https://arxiv.org/pdf/2106.08532.pdf>[paper]</a></li> <li>[Arxiv 21] <strong>Preserve, Promote, or Attack? GNN Explanation via Topology Perturbation</strong> <a href=https://arxiv.org/pdf/2103.13944.pdf>[paper]</a></li> <li>[Arxiv 21] <strong>Learnt Sparsification for Interpretable Graph Neural Networks</strong> <a href=https://arxiv.org/pdf/2106.12920.pdf>[paper]</a></li> <li>[ICML workshop 21] <strong>GCExplainer: Human-in-the-Loop Concept-based Explanations for Graph Neural Networks</strong> <a href=https://arxiv.org/pdf/2107.11889.pdf>[paper]</a></li> <li>[ICML workshop 21] <strong>Reliable Graph Neural Network Explanations Through Adversarial Training</strong> <a href=https://arxiv.org/pdf/2106.13427.pdf>[paper]</a></li> <li>[ICML workshop 21] <strong>Reimagining GNN Explanations with ideas from Tabular Data</strong> <a href=https://arxiv.org/pdf/2106.12665.pdf>[paper]</a></li> <li>[ICML workshop 21] <strong>Towards Automated Evaluation of Explanations in Graph Neural Networks</strong> <a href=https://arxiv.org/pdf/2106.11864.pdf>[paper]</a></li> <li>[ICDM 2021] <strong>GNES: Learning to Explain Graph Neural Networks</strong> <a href=https://cs.emory.edu/~lzhao41/materials/papers/GNES.pdf>[paper]</a></li> <li>[ICDM 2021] <strong>GCN-SE: Attention as Explainability for Node Classification in Dynamic Graphs</strong> <a href=https://arxiv.org/abs/2110.05598>[paper]</a></li> <li>[ICDM 2021] <strong>Multi-objective Explanations of GNN Predictions</strong> <a href=https://arxiv.org/abs/2111.14651>[paper]</a></li> <li>[CIKM 2021] <strong>Towards Self-Explainable Graph Neural Network</strong> <a href=https://arxiv.org/abs/2108.12055>[paper]</a></li> <li>[ECML PKDD 2021] <strong>GraphSVX: Shapley Value Explanations for Graph Neural Networks</strong> <a href=https://arxiv.org/abs/2104.10482>[paper]</a></li> <li>[WiseML 2021] <strong>Explainability-based Backdoor Attacks Against Graph Neural Networks</strong> <a href=https://dl.acm.org/doi/pdf/10.1145/3468218.3469046>[paper]</a></li> <li>[IJCNN 21] <strong>MEG: Generating Molecular Counterfactual Explanations for Deep Graph Networks</strong> <a href=https://arxiv.org/pdf/2104.08060.pdf>[paper]</a></li> <li>[ICCSA 2021] <strong>Understanding Drug Abuse Social Network Using Weighted Graph Neural Networks Explainer</strong> <a href=https://link.springer.com/chapter/10.1007%2F978-3-030-86970-0_5>[paper]</a></li> <li>[NeSy 21] <strong>A New Concept for Explaining Graph Neural Networks</strong> <a href=http://ceur-ws.org/Vol-2986/paper1.pdf>[paper]</a></li> <li>[Information Fusion 21] <strong>Towards multi-modal causability with Graph Neural Networks enabling information fusion for explainable AI</strong> <a href=https://www.sciencedirect.com/science/article/pii/S1566253521000142?via%3Dihub>[paper]</a></li> <li>[Patterns 21] <strong>hcga: Highly Comparative Graph Analysis for network phenotyping</strong> <a href=https://www.biorxiv.org/content/10.1101/2020.09.25.312926v2>[paper]</a></li> </ol> <h2 id=year-2020-and-before>Year 2020 and Before<a class=headerlink href=#year-2020-and-before title="Permanent link">&para;</a></h2> <ol> <li>[NeurIPS 2020] <strong>Parameterized Explainer for Graph Neural Network</strong>.<a href=https://arxiv.org/abs/2011.04573>[paper]</a></li> <li>[NeurIPS 2020] <strong>PGM-Explainer: Probabilistic Graphical Model Explanations for Graph Neural Networks</strong> <a href=https://arxiv.org/pdf/2010.05788.pdf>[paper]</a></li> <li>[KDD 2020] <strong>XGNN: Towards Model-Level Explanations of Graph Neural Networks</strong> <a href=https://dl.acm.org/doi/10.1145/3394486.3403085>[paper]</a></li> <li>[ACL 2020]<strong>GCAN: Graph-aware Co-Attention Networks for Explainable Fake News Detection on Social Media</strong>. <a href=https://arxiv.org/pdf/2004.11648.pdf>paper</a></li> <li>[Arxiv 2020] <strong>Graph Neural Networks Including Sparse Interpretability</strong> <a href=https://arxiv.org/abs/2007.00119>[paper]</a></li> <li>[NeurIPS Workshop 20] <strong>Towards explainable message passing networks for predicting carbon dioxide adsorption in metal-organic frameworks</strong> <a href=https://arxiv.org/abs/2012.03723>[paper]</a></li> <li>[ICML workstop 2020] <strong>Contrastive Graph Neural Network Explanation</strong> <a href=https://arxiv.org/pdf/2010.13663.pdf>[paper]</a></li> <li>[ICML workstop 2020] <strong>Towards Explainable Graph Representations in Digital Pathology</strong> <a href=https://arxiv.org/pdf/2007.00311.pdf>[paper]</a></li> <li>[NeurIPS workshop 2020] <strong>Explaining Deep Graph Networks with Molecular Counterfactuals</strong> <a href=https://arxiv.org/pdf/2011.05134.pdf>[paper]</a></li> <li>[DataMod 2020] <strong>Exploring Graph-Based Neural Networks for Automatic Brain Tumor Segmentation"</strong> <a href=https://link.springer.com/chapter/10.1007%2F978-3-030-70650-0_2>[paper]</a></li> <li>[OpenReview 20] <strong>A Framework For Differentiable Discovery Of Graph Algorithms</strong> <a href="https://openreview.net/pdf?id=ueiBFzt7CiK">[paper]</a></li> <li>[OpenReview 20] <strong>Causal Screening to Interpret Graph Neural Networks</strong> <a href="https://openreview.net/pdf?id=nzKv5vxZfge">[paper]</a></li> <li>[Arxiv 20] <strong>Understanding Graph Neural Networks from Graph Signal Denoising Perspectives</strong> <a href=https://arxiv.org/pdf/2006.04386.pdf>[paper]</a></li> <li>[Arxiv 20] <strong>Understanding the Message Passing in Graph Neural Networks via Power Iteration</strong> <a href=https://arxiv.org/pdf/2006.00144.pdf>[paper]</a></li> <li>[Arxiv 20] <strong>xERTE: Explainable Reasoning on Temporal Knowledge Graphs for Forecasting Future Links</strong> <a href=https://arxiv.org/pdf/2006.00144.pdf>[paper]</a></li> <li>[IJCNN 20] <strong>GCN-LRP explanation: exploring latent attention of graph convolutional networks</strong>] <a href=https://ieeexplore.ieee.org/abstract/document/9207639>[paper]</a></li> <li>[CD-MAKE 20] <strong>Explain Graph Neural Networks to Understand Weighted Graph Features in Node Classification</strong> <a href=https://arxiv.org/abs/2002.00514>[paper]</a> </li> <li>[ICDM 19] <strong>Scalable Explanation of Inferences on Large Graphs</strong><a href=https://arxiv.org/abs/1908.06482>[paper]</a> </li> </ol> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title=最后更新> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1-2.1-2M12.5 7v5.2l4 2.4-1 1L11 13V7h1.5M11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2v1.8Z"/></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">October 8, 2024</span> </span> <span class=md-source-file__fact> <span class=md-icon title=贡献者> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 4a4 4 0 0 1 4 4 4 4 0 0 1-4 4 4 4 0 0 1-4-4 4 4 0 0 1 4-4m0 10c4.42 0 8 1.79 8 4v2H4v-2c0-2.21 3.58-4 8-4Z"/></svg> </span> <nav> <a href=mailto:chinesechenqa@163.com>Kian Chen</a> </nav> </span> </aside> <!-- Insert generated snippet here --> <script src=https://giscus.app/client.js data-repo=PKUFlyingPig/cs-self-learning data-repo-id=R_kgDOGP67ng data-category=Announcements data-category-id=DIC_kwDOGP67ns4COM9Q data-mapping=title data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=light_protanopia data-lang=zh-CN data-loading=lazy crossorigin=anonymous async>
</script> <!-- Synchronize Giscus theme with palette --> <script>
var giscus = document.querySelector("script[src*=giscus]")

// Set palette on initial load
var palette = __md_get("__palette")
if (palette && typeof palette.color === "object") {
    var theme = palette.color.scheme === "slate"
    ? "dark_protanopia"
    : "light_protanopia"

    // Instruct Giscus to set theme
    giscus.setAttribute("data-theme", theme) 
}

// Register event handlers after documented loaded
document.addEventListener("DOMContentLoaded", function() {
    var ref = document.querySelector("[data-md-component=palette]")
    ref.addEventListener("change", function() {
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
        var theme = palette.color.scheme === "slate"
        ? "dark_protanopia"
        : "light_protanopia"

        // Instruct Giscus to change theme
        var frame = document.querySelector(".giscus-frame")
        frame.contentWindow.postMessage(
        { giscus: { setConfig: { theme } } },
        "https://giscus.app"
        )
    }
    })
})
</script> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg> 回到页面顶部 </button> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024-present <a href=https://github.com/Kian-Chen target=_blank rel="noopener noreferrer">Kian Chen</a> </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://Kian-Chen.github.io/ExplainGNNReading target=_blank rel=noopener title=Kian-Chen.github.io class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": ".", "features": ["content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.footnote.tooltips", "content.tooltips", "header.autohide", "navigation.indexes", "navigation.instant.prefetch", "navigation.sections", "navigation.tracking", "navigation.top", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "assets/javascripts/workers/search.c011b7c0.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script> <script src=assets/javascripts/bundle.7389ff0e.min.js></script> <script src=javascripts/mathjax.js></script> <script src=https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>